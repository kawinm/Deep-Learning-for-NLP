{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "from torchtext.data import get_tokenizer\n",
    "import torchtext\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "# import xlsxwriter module\n",
    "import xlsxwriter\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = xlsxwriter.Workbook('kawin.xlsx')\n",
    " \n",
    "worksheet = workbook.add_worksheet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176009\n"
     ]
    }
   ],
   "source": [
    "TEST_DATA_PATH  = './EnglishDictionary.csv'\n",
    "TOP_K           = 1\n",
    "MODEL_NAME      = \"./3dbert_mask_lr2_more.pt\"\n",
    "\n",
    "dataset = []\n",
    "with open(TEST_DATA_PATH) as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        dataset.append((row[3], row[0]))\n",
    "\n",
    "# TODO: Check if the first row is header or actual values\n",
    "\n",
    "dataset = dataset[1:]\n",
    "\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForMaskedLM\n",
    "import torch\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertForMaskedLM.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_de = open(\"en-de.txt\", \"r\").readlines()\n",
    "\n",
    "en_de_dict = {}\n",
    "\n",
    "for i in en_de:\n",
    "    en, de = i.split(\" \")\n",
    "    if en in en_de_dict:\n",
    "        en_de_dict[en] = en_de_dict[en] + [de]\n",
    "    else:\n",
    "        en_de_dict[en] = [de]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DistilBertForMaskedLM.from_pretrained(\"distilbert-base-uncased\")\n",
    "device = torch.device(\"cuda:2\")\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_NAME))\n",
    "model.to(device)\n",
    "\n",
    "#loss_fn = F.cross_entropy\n",
    "opt = optim.Adam(model.parameters(), lr = 0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['ein', 'eine', 'einen', 'einem', 'ein', 'eine', 'aleph']\n",
      "['a', 'aleph', 'alephph', 'phoenil', 'phphthhtph']\n",
      "1 ['ein', 'eine', 'einen', 'einem', 'ein', 'eine', 'sehen', 'schau', 'see', 'siehe', 'ansehen']\n",
      "['a', 'see', 'se', '-a', 'me', '-', '-e']\n",
      "2 ['adjektiv']\n",
      "['adjective', 'ul', '-', 'idmina', 'idimina', 'heteroolica']\n",
      "3 ['nam']\n",
      "['nam', 'twentyoat', 'twenty', '-n', 'su', '-', 'an', 'ci']\n",
      "4 ['eine', 'ein', 'ein', 'eine', 'einer', 'einen', 'einem', 'ann']\n",
      "['an', 'ann', 'ahiln', 'aa', \"'n\", \"aa''e\"]\n",
      "5 ['ein', 'eine', 'einen', 'einem', 'ein', 'eine']\n",
      "['a', 'preps', 'prompts', 'antapsits', 'anta', '-sits']\n",
      "6 ['ein', 'eine', 'einen', 'einem', 'ein', 'eine', 'eine', 'ein', 'ein', 'eine', 'einer', 'einen', 'einem']\n",
      "['a', 'an', \"'n\", \"a''n\", \"a''\", '-e']\n",
      "7 ['hase']\n",
      "['ye', 'hase', \"'a\", \"he''h\", \"t''\", \"'h\"]\n",
      "8 ['null', 'spe']\n",
      "['null', 'spe', 'explee', 'anaspplee', 'anaphphplee']\n",
      "9 ['ein', 'eine', 'einen', 'einem', 'ein', 'eine']\n",
      "['a', 'ab', '-', \"ana'-\", \"ab''\", \"ab'''-\"]\n",
      "10 ['grade', 'klasse', 'grad', 'besoldungsgruppe']\n",
      "['grade', 'under', 'first', '-', 'a', \"sub'-\", 'd', \"-'-\"]\n",
      "11 ['marc']\n",
      "['marc', 'aader', 'aaaaum', 'aa', '-', '-um', \"ar'-\"]\n",
      "12 ['hase', 'hare', 'hasen', 'bauch']\n",
      "['hare', 'bunt', 'ant', '-t', 'ory', '-e', \"ant'-\", '-', 'foot']\n",
      "13 ['panda']\n",
      "['panda', 'laland', 'lalandi', 'lal', '-bot', \"z'-\", '-t']\n",
      "14 ['harun', 'aaron']\n",
      "['aaron', 'aaronic', 'aaronicic', 'aaronichric', 'aaronapophaic']\n",
      "15 ['babylonischen']\n",
      "['babylonian', 'aaronite', 'headaic', 'headaadaic', 'heeroopadaic']\n",
      "16 ['waage', 'bilanz', 'balance', 'gleichgewicht']\n",
      "['balance', 'bi', 'rod', 'ampuceus', 'amppiouce', \"ci's\", 's']\n",
      "17 ['spike']\n",
      "['spike', 'roseer', 'mollein', 'lady', '-', 'rod', 'ladyg']\n",
      "18 ['von']\n",
      "['ab', '-', 'abo', 'aboo', 'abao']\n",
      "19 ['von']\n",
      "['ab', 'senh', 'temuh', 'teah', '-h', '-']\n",
      "20 ['mose', 'musa', 'bata']\n",
      "['musa', 'bata', 'ma', '-a', '-', 'hemp']\n",
      "21 ['blendung']\n",
      "['glare', 'tincolor', 'b', '-e', 'redph', '-te', 'melhr', '-', 'blind']\n",
      "22 ['zulage', 'taschengeld', 'freibetrag']\n",
      "['allowance', 'abation', 'abacination', 'abacinatetion', 'abacinatingtication']\n",
      "23 ['abbrechen', 'absagen']\n",
      "['cancel', 'abaculus', 'abacuculus', 'abacucuculus', 'tessap', '-', '-culus']\n",
      "24 ['buchhalter', 'steuerberater', 'rechnungswesen', 'buchhaltung', 'abakus']\n",
      "['accountant', 'abacus', 'abacist', 'abaciscist', 'abacis', '-pist']\n",
      "25 ['forward', 'vorwärts', 'stürmer', 'rückwärts']\n",
      "['forwards', 'backward', 'backwardward', 'postapwardward', 'postaptrotrol']\n",
      "26 ['hinter', 'dahinter']\n",
      "['behind', 'foreward', 'forereaward', 'foretrotrol', 'anttrotrotrol']\n",
      "27 []\n",
      "['aback', 'backsown', 'countermasown', 'counter', '-masown', '-']\n",
      "28 ['abakus']\n",
      "['aback', 'abacus', 'abacusus', 'abaap', '-e', 'appr', '-', '-us']\n",
      "29 ['ventrale', 'ventralen', 'und', 'wirbelsäule']\n",
      "['ventral', 'actinal', 'antitominal', 'antiortominal', 'anterooptominal']\n",
      "30 ['vergewaltigungen', 'raps', 'vergewaltigung', 'vergewaltigt', 'vergewaltigen']\n",
      "['rape', 'abaing', 'aba', '-ing', 'sw', '-scaing', '-']\n",
      "31 ['stampede', 'ansturm']\n",
      "['stampede', 'abaer', 'abacartor', 'abaucriot', 'vecar', '-hat']\n",
      "32 []\n",
      "['##pods', 'abacula', 'abaculi', 'abaculili', 'abaculolili']\n",
      "33 ['vasen', 'vase']\n",
      "['vase', 'tesstile', 'scmpa', 'marap', '-e', \"sc'-\"]\n",
      "34 ['aba']\n",
      "['aba', 'abaci', 'abacuses', 'abacuscees', 'abacus', '-cees']\n",
      "35 ['aba']\n",
      "['aba', 'abaci', 'abacuses', 'abacuscees', 'abacus', '-cees']\n",
      "36 ['vasen', 'vase']\n",
      "['vase', 'abayx', 'abaplcus', 'scap', '-um', '-']\n",
      "37 ['counter', 'schalter', 'zähler']\n",
      "['counter', 'quanr', 'faquan', 'dthramn', 'dhrumramh']\n",
      "38 ['hauptstadt', 'kapital']\n",
      "['capital', 'abaa', 'epitle', 'epitita', 'ciitchita']\n",
      "39 ['verkleidung', 'panel']\n",
      "['panel', 'abayx', 'scbasle', 'scapmple', 'scapophedus']\n",
      "40 ['schrank']\n",
      "['cupboard', 'trayboard', 'cupafr', 'cupaf', '-r', 'cass', '-', 'de', 'tray']\n",
      "41 ['einhorn']\n",
      "['unicorn', 'rhinofish', 'rhinocerine', 'rhinoeroodid', 'sceroopodum']\n",
      "42 ['luzifer']\n",
      "['lucifer', 'apyon', 'apollyon', 'aperodeon', 'apapopdeon']\n",
      "43 ['pit', 'grube']\n",
      "['pit', 'helle', 'hell', '-p', '-', '-h']\n",
      "44 ['aba']\n",
      "['aba', 'abaft', 'abaftt', '-ft', '-', '-e']\n",
      "45 ['aba']\n",
      "['aba', 'abaft', '-ftft', '-']\n",
      "46 []\n",
      "['##isance', 'obeisance', 'obeisancence', 'observatnce', 'obssumquance']\n",
      "47 ['chrome', 'chrom']\n",
      "['chrome', 'picite', 'xyrine', 'xyrche', 'xyropphae']\n",
      "48 ['geschlagen', 'verprügelt', 'besiegt']\n",
      "['beaten', 'abased', 'abamped', 'dimfied', 'discomm', '-ed']\n",
      "49 ['übersetzung', 'übersetzt', 'übersetzen', 'übersetzten']\n",
      "['translate', 'devrogate', 'diseanate', 'disgitte', 'disasapite']\n",
      "50 ['abweisen', 'verwerfen']\n",
      "['dismiss', 'demiede', 'dioie', 'disarangte', 'disasariate']\n",
      "51 ['alien', 'ausländer', 'fremd']\n",
      "['alien', 'alienend', 'diemete', 'disaculate', 'disampciaze']\n",
      "52 ['gleichgültigkeit']\n",
      "['indifference', 'abatation', 'abalienation', 'abalienatation', 'abalienatnatment']\n",
      "53 ['schnecken', 'schnecke']\n",
      "['snail', 'earfish', 'hal', '-', 'shell', 'sea']\n",
      "54 ['aufgeben']\n",
      "['abandon', 'waiess', 'dioie', 'disaoite', 'disasaciate']\n",
      "55 ['abweisen', 'verwerfen']\n",
      "['dismiss', 'demipel', 'exoiish', 'dispmbote', 'disppeciate']\n",
      "56 ['aufgabe', 'aufgabe']\n",
      "['abandoning', 'forlieing', 'disagaing', 'disaccgaing']\n",
      "57 ['aufgabe', 'aufgabe']\n",
      "['abandoning', 'forlieing', 'disagaing', 'disaccgaing']\n",
      "58 ['abweisen', 'verwerfen']\n",
      "['dismiss', 'demiject', 'dispe', 'dispmbote', 'dispspmbote']\n",
      "59 ['vorzulegen', 'übermitteln', 'einreichen', 'senden']\n",
      "['submit', 'renoess', 'foroie', 'disaoite', 'disappeciate']\n",
      "60 ['beenden', 'aufgeben', 'aufhören']\n",
      "['quit', 'avet', 'ev', '-e', 'self', '-', 'inde', 'de']\n",
      "61 ['aufgeben']\n",
      "['abandon', 'reinsmise', 'relait', 'dilinciat', 'di', '-quiciate']\n",
      "62 ['aufgeben', 'aufgabe', 'verzicht']\n",
      "['abandonment', 'derelictment', 'repession', 'relinessment', 'relinquishment']\n",
      "63 ['impuls', 'impulse']\n",
      "['impulse', 'impment', 'impmpion', 'impmpmption', 'exmpmpmption']\n",
      "64 ['aufgegeben', 'verlassenen', 'verlassen', 'stillgelegt', 'zurückgelassen', 'aufgegeben', 'verlassenen']\n",
      "['abandoned', 'desertless', 'forsaken', 'forsakened', 'forsa', '-', '-ed']\n",
      "65 ['aufgegeben', 'verlassenen', 'verlassen', 'stillgelegt', 'zurückgelassen']\n",
      "['abandoned', 'rep', '-', 'abrepld', 'ar', '-d']\n",
      "66 ['unruhen', 'unruhe']\n",
      "['unrest', 'unrestly', 'unrestrainedly', 'diprtlely', 'di', '-', '-edly']\n",
      "67 []\n",
      "['##ee', 'derelictee', 'appeeee', 'dispeee', 'diemdoteee']\n",
      "68 ['aufgabe']\n",
      "['abandoning', 'abandoner', 'demilieer', 'disaciator', 'disapliont']\n",
      "69 ['aufgeben', 'aufgabe', 'verzicht']\n",
      "['abandonment', 'derelictment', 'redession', 'disolessment', 'dilinquishment']\n",
      "70 ['aufgeben', 'aufgabe', 'verzicht']\n",
      "['abandonment', 'reinsment', 'reossment', 're', '-issment', '-', '-shment']\n",
      "71 ['aufgeben', 'aufgabe', 'verzicht']\n",
      "['abandonment', 'quitation', 'relaiion', 'relinquiment', 'relinquishment']\n",
      "72 ['aufgeben', 'aufgabe', 'verzicht', 'desertion']\n",
      "['abandonment', 'desertion', 'repesstion', 'disosantion', 'disa', '-sanion']\n",
      "73 ['aufgeben', 'aufgabe', 'verzicht']\n",
      "['abandonment', 'faiance', 'delpenss', 'diplpenion', 'disapenpence']\n",
      "74 ['grundstück', 'eigenschaft', 'immobilien', 'immobilie', 'eigentum']\n",
      "['property', 'abammon', 'abaapge', 'abaspfium', 'diap', '-', '-um']\n",
      "75 ['von']\n",
      "['ab', 'abnet', 'abne', '-t', '-']\n",
      "76 ['kommode', 'brust', 'brustkorb', 'truhe']\n",
      "['chest', 'cass', 'palm', 'cassmp', 'koap', '-', 'koa']\n",
      "77 ['aba']\n",
      "['aba', 'abation', 'abannament', 'abannicement', 'abannicecement']\n",
      "78 ['exil', 'verbannung']\n",
      "['exile', 'banation', 'abessation', 'abseity', 'absetiity']\n",
      "79 []\n",
      "['##osis', 'volosis', 'diarthosis', 'diaarthhysis', 'schyodhysis']\n",
      "80 ['aba']\n",
      "['aba', 'abased', 'abaseg', 'abase', 'abaing', '-', '-ing']\n",
      "81 ['aba']\n",
      "['aba', 'abased', 'abaseg', 'abase', 'abaing', '-', '-ing']\n",
      "82 ['aba']\n",
      "['aba', 'abase', 'disectase', 'disesepese']\n",
      "83 ['demi']\n",
      "['demi', 'demioop', 'decsouate', 'dispmbote', 'disasplitate']\n",
      "84 ['gesenkt', 'abgesenkt']\n",
      "['lowered', 'demid', 'decsod', 'despebte', 'disppehabte']\n",
      "85 ['neigen']\n",
      "['prone', 'abased', 'underfesed', 'defefeous', 'defra', '-ceous']\n",
      "86 ['dead', 'tote', 'tot', 'toten']\n",
      "['dead', 'ably', 'abjectly', 'abspjectly', 'displojectly']\n",
      "87 ['depressionen', 'senke', 'wirtschaftskrise', 'depression', 'tiefstand']\n",
      "['depression', 'abasation', 'abasement', 'abaseebment', 'abaseplisiment']\n",
      "88 ['aba']\n",
      "['aba', 'abaser', 'abasesr', 'abasesssor', 'abases', '-sisr']\n",
      "89 ['aba']\n",
      "['aba', 'abashing', 'abasheeing', 'abash', '-', '-ing']\n",
      "90 ['aba']\n",
      "['aba', 'abashing', 'abasheeing', 'abash', '-', '-ing']\n",
      "91 ['smash', 'zerschlagen', 'zertrümmert']\n",
      "['smash', 'decord', 'discopret', 'dimfote', 'disamfote']\n",
      "92 []\n",
      "['harshly', 'abashed', 'abashedly', 'abashshedly', 'abash', '-shedly']\n",
      "93 ['verwechslung', 'verwirren', 'durcheinander', 'verwirrung']\n",
      "['confusion', 'abashed', 'abashment', 'abashshment', 'abash', '-shment']\n",
      "94 ['aba']\n",
      "['aba', 'abassi', 'abassis', 'abassices', '-ces']\n",
      "95 ['persischen', 'persische', 'persisch', 'perser']\n",
      "['persian', 'peran', 'perzarh', 'perzarbh', 'dbb', '-h']\n",
      "96 []\n",
      "['##utable', 'abatable', 'abata', 'abable', 'abate', 'facible']\n",
      "97 ['aba']\n",
      "['aba', 'abated', 'abatete', 'abate', 'abating', '-teting']\n",
      "98 ['aba']\n",
      "['aba', 'abated', 'abatete', 'abate', 'abating', '-teting']\n",
      "99 ['sturz', 'stürzen']\n",
      "['overthrow', 'abae', 'difoe', 'dispmboe', 'dispppfote']\n"
     ]
    }
   ],
   "source": [
    "for ip in range(len(dataset)):\n",
    "    pred_words = []\n",
    "    pred_word_english = []\n",
    "    for j in range(1, 6):\n",
    "        inputs = tokenizer(\"[MASK] \"*j + dataset[ip][0], return_tensors=\"pt\")\n",
    "\n",
    "        inputs.to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "\n",
    "        # retrieve index of [MASK]\n",
    "        mask_token_index = (inputs.input_ids == tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0]\n",
    "\n",
    "        predicted_token_id = logits[0, mask_token_index].argmax(axis=-1)\n",
    "        pred = tokenizer.decode(predicted_token_id)\n",
    "\n",
    "        if len(pred.split(\" \")) == 1:\n",
    "            if pred in en_de_dict:\n",
    "                for predictions in en_de_dict[pred]:\n",
    "                    if predictions not in pred_words:\n",
    "                        pred_words.append(predictions[:-1])\n",
    "        for english_word in pred.split(\" \"):\n",
    "            if english_word not in pred_word_english:\n",
    "                pred_word_english.append(english_word)\n",
    "    print(ip, pred_words)\n",
    "    print(pred_word_english)\n",
    "    if len(pred_words) >= TOP_K:\n",
    "        if TOP_K == 1:\n",
    "            worksheet.write('A'+str(ip+1), pred_words[0])\n",
    "    else:\n",
    "        if TOP_K == 1:\n",
    "            ii = 0\n",
    "            while '#' in pred_word_english[ii]:\n",
    "                ii += 1\n",
    "            worksheet.write('A'+str(ip+1), pred_word_english[ii])\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in lr 1 - ep 4 11.43\n",
    "lr 2 ep 2 11.18\n",
    "more 3 1063"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82c36bf2dc7bc97628b9e43543d03433a2e60a09cf06bbc88105c7bffe751e99"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
