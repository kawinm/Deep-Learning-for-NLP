{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/home/kawinm/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "import spacy\n",
    "from torchtext.vocab import GloVe, FastText\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "pos_set = []\n",
    "neg_set = []\n",
    "with open(\"./Train dataset.csv\", encoding='utf-8') as csvf:\n",
    "    data = csv.DictReader(csvf)\n",
    "\n",
    "    for rows in data:\n",
    "\n",
    "        # Removing punctuations\n",
    "        review = rows['review'].replace('<br />', \" \", -1)\n",
    "\n",
    "        if rows['sentiment'] == 'positive':\n",
    "            pos_set.append(review)\n",
    "        else:\n",
    "            neg_set.append(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed = 42):\n",
    "    '''\n",
    "        For Reproducibility: Sets the seed of the entire notebook.\n",
    "    '''\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    # Sets a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19885 20115\n"
     ]
    }
   ],
   "source": [
    "print(len(pos_set), len(neg_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Positive Finished ---\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import get_tokenizer\n",
    "\n",
    "# Downloads GloVe and FastText\n",
    "global_vectors = GloVe(name='840B', dim=300)\n",
    "\n",
    "# ----------- Text Preprocessing -----------\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "data_set = []\n",
    "vocab = []\n",
    "\n",
    "chars_to_remove = ['--', '`', '~', '<', '>', '*', '{', '}', '^', '=', '_', '[', ']', '|', '- ', '.', ',', '<br />']\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "for line in pos_set:\n",
    "\n",
    "    # Tokenizes the input text into words\n",
    "    tokens = tokenizer(line)\n",
    "\n",
    "    data_set.append((tokens, 1))\n",
    "    # Adds the extracted words to a list\n",
    "    vocab.extend(tokens)\n",
    "\n",
    "\n",
    "print(\"--- Positive Finished ---\")\n",
    "\n",
    "for line in neg_set:\n",
    "\n",
    "    # Tokenizes the input text into words\n",
    "    tokens = tokenizer(line)\n",
    "\n",
    "    data_set.append((tokens, 0))\n",
    "    # Adds the extracted words to a list\n",
    "    vocab.extend(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in the vocabulary:  130959\n"
     ]
    }
   ],
   "source": [
    "#len(set(vocab))\n",
    "\n",
    "# Stores all the unique words in the dataset and their frequencies\n",
    "vocabulary = {}\n",
    "\n",
    "# Calculates the frequency of each unique word in the vocabulary\n",
    "for word in vocab:\n",
    "    if word in vocabulary:\n",
    "        vocabulary[word] += 1\n",
    "    else:\n",
    "        vocabulary[word] = 1\n",
    "\n",
    "print(\"Number of unique words in the vocabulary: \", len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stores the integer token for each unique word in the vocabulary\n",
    "ids_vocab = {}\n",
    "\n",
    "id = 0\n",
    "\n",
    "# Assigns words in the vocabulary to integer tokens\n",
    "for word, v in vocabulary.items():\n",
    "    ids_vocab[word] = id\n",
    "    id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization function\n",
    "def tokenize(corpus, ids_vocab):\n",
    "    \"\"\"\n",
    "        Converts words in the dataset to integer tokens\n",
    "    \"\"\"\n",
    "\n",
    "    tokenized_corpus = []\n",
    "    for line, sentiment in corpus:\n",
    "        new_line = []\n",
    "        for i, word in enumerate(line):\n",
    "            if word in ids_vocab and (i == 0 or word != line[i-1]):\n",
    "                new_line.append(ids_vocab[word])\n",
    "\n",
    "        new_line = torch.Tensor(new_line).long()\n",
    "        tokenized_corpus.append((new_line, sentiment))\n",
    "\n",
    "    return tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_corpus = tokenize(data_set, ids_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'vocab' from 'torchtext.vocab' (/raid/home/kawinm/miniconda3/lib/python3.9/site-packages/torchtext/vocab.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/raid/home/kawinm/dlnlp/assgn_2/model.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.192.30.31/raid/home/kawinm/dlnlp/assgn_2/model.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchtext\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvocab\u001b[39;00m \u001b[39mimport\u001b[39;00m vocab\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.192.30.31/raid/home/kawinm/dlnlp/assgn_2/model.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m Counter, OrderedDict\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.192.30.31/raid/home/kawinm/dlnlp/assgn_2/model.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Creating the vocabulary from the tokens of words\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'vocab' from 'torchtext.vocab' (/raid/home/kawinm/miniconda3/lib/python3.9/site-packages/torchtext/vocab.py)"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import vocab\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "# Creating the vocabulary from the tokens of words\n",
    "counter = Counter(vocabulary)\n",
    "\n",
    "\"\"\"\n",
    "counter_filtered = {}\n",
    "\n",
    "for k, v in counter.items():\n",
    "    if v > 3:\n",
    "        counter_filtered[k] = v\n",
    "\"\"\"\n",
    "        \n",
    "sorted_by_freq_tuples = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "\n",
    "# Adding <unk> token and default index\n",
    "unk_token = '<unk>'\n",
    "\n",
    "# Making default index same as index of unk_token\n",
    "default_index = 0\n",
    "v2 = Vocab(ordered_dict, specials=[unk_token])\n",
    "v2.set_default_index(default_index)\n",
    "\n",
    "print(\"Number of words in Vocabulary: \", v2.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 300\n",
    "\n",
    "embeds = torch.zeros(len(ids_vocab) + 1, emb_dim)\n",
    "\n",
    "for token, idx in ids_vocab.items():\n",
    "    embeds[idx] = global_vectors[token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[20677,  1553,    25,  ...,     0,     0,     0],\n",
      "        [  119,   974,    51,  ...,     0,     0,     0],\n",
      "        [  119,   446,   321,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  787,    36,    51,  ...,     0,     0,     0],\n",
      "        [  119,  3966,   143,  ...,     0,     0,     0],\n",
      "        [    2,    32,   278,  ...,     0,     0,     0]]), tensor([0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 0.]))\n"
     ]
    }
   ],
   "source": [
    "# Train-Valid split of 95-05\n",
    "def split_indices(n, val_pct):\n",
    "\n",
    "    # Determine size of Validation set\n",
    "    n_val = int(val_pct * n)\n",
    "\n",
    "    # Create random permutation of 0 to n-1\n",
    "    idxs = np.random.permutation(n)\n",
    "    return idxs[n_val:], idxs[:n_val]\n",
    "\n",
    "train_pos_indices, val_pos_indices = split_indices(len(pos_set), 0.2)\n",
    "train_neg_indices, val_neg_indices = split_indices(len(neg_set), 0.2)\n",
    "\n",
    "train_indices = np.concatenate((train_pos_indices, train_neg_indices+len(pos_set)-1))\n",
    "val_indices = np.concatenate((val_pos_indices, val_neg_indices+len(pos_set)-1))\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# ----------- Batching the data -----------\n",
    "def collate_fn(instn):\n",
    "\n",
    "    sentence = [x[0] for x in instn]\n",
    "    sentence = pad_sequence(sentence, batch_first=True, padding_value=0)\n",
    "\n",
    "    labels = torch.Tensor([x[1] for x in instn])\n",
    "\n",
    "    return (sentence, labels)\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_sampler   = SubsetRandomSampler(train_indices)\n",
    "train_loader    = DataLoader(token_corpus, batch_size, sampler=train_sampler, collate_fn=collate_fn)\n",
    "\n",
    "val_sampler     = SubsetRandomSampler(val_indices)\n",
    "val_loader      = DataLoader(token_corpus, batch_size, sampler=val_sampler, collate_fn=collate_fn)\n",
    "\n",
    "for i in train_loader:\n",
    "    print(i)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Model -----------\n",
    "class BILSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, embeds):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embeddings = nn.Embedding.from_pretrained(embeds, padding_idx=0)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size = 300, hidden_size = 200, num_layers =1, batch_first = True, bidirectional = True)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.lin1 = nn.Linear(400, 100)\n",
    "        self.lin2 = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, xb, tsne = False):\n",
    "\n",
    "        x = self.embeddings(xb)\n",
    "        x, y = self.lstm(x)\n",
    "        x = torch.cat((y[0][0, :, :], y[0][1, :, :]), dim = 1)\n",
    "        x = x.squeeze(dim=0)\n",
    "        x = self.lin1(x)\n",
    "\n",
    "        if tsne == True:\n",
    "            return x \n",
    "\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.lin2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "model = BILSTM(embeds)\n",
    "model.to(device)\n",
    "opt_c = torch.optim.Adagrad(model.parameters(), lr = 0.001)\n",
    "# loss_fn_c = F.cross_entropy - Tried Cross Entropy with log_softmax output function - gave similar results\n",
    "loss_fn_c = F.binary_cross_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:24<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1  Training Loss:  145.12107849121094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 48/63 [00:02<00:00, 20.54it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.29 GiB (GPU 0; 39.59 GiB total capacity; 19.48 GiB already allocated; 170.62 MiB free; 21.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/raid/home/kawinm/dlnlp/assgn_2/model.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.192.30.31/raid/home/kawinm/dlnlp/assgn_2/model.ipynb#ch0000012vscode-remote?line=41'>42</a>\u001b[0m xb \u001b[39m=\u001b[39m xb\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.192.30.31/raid/home/kawinm/dlnlp/assgn_2/model.ipynb#ch0000012vscode-remote?line=42'>43</a>\u001b[0m yb \u001b[39m=\u001b[39m yb\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.192.30.31/raid/home/kawinm/dlnlp/assgn_2/model.ipynb#ch0000012vscode-remote?line=44'>45</a>\u001b[0m y_hat \u001b[39m=\u001b[39m model(xb)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.192.30.31/raid/home/kawinm/dlnlp/assgn_2/model.ipynb#ch0000012vscode-remote?line=45'>46</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn_c(y_hat\u001b[39m.\u001b[39msqueeze(), yb)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.192.30.31/raid/home/kawinm/dlnlp/assgn_2/model.ipynb#ch0000012vscode-remote?line=47'>48</a>\u001b[0m val_epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/raid/home/kawinm/dlnlp/assgn_2/model.ipynb Cell 12'\u001b[0m in \u001b[0;36mBILSTM.forward\u001b[0;34m(self, xb, tsne)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.192.30.31/raid/home/kawinm/dlnlp/assgn_2/model.ipynb#ch0000011vscode-remote?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, xb, tsne \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.192.30.31/raid/home/kawinm/dlnlp/assgn_2/model.ipynb#ch0000011vscode-remote?line=16'>17</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(xb)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.192.30.31/raid/home/kawinm/dlnlp/assgn_2/model.ipynb#ch0000011vscode-remote?line=17'>18</a>\u001b[0m     x, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.192.30.31/raid/home/kawinm/dlnlp/assgn_2/model.ipynb#ch0000011vscode-remote?line=18'>19</a>\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((y[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m, :, :], y[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m, :, :]), dim \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.192.30.31/raid/home/kawinm/dlnlp/assgn_2/model.ipynb#ch0000011vscode-remote?line=19'>20</a>\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39msqueeze(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:761\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    760\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 761\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    762\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    763\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    764\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    765\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.29 GiB (GPU 0; 39.59 GiB total capacity; 19.48 GiB already allocated; 170.62 MiB free; 21.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# ----------- Main Training Loop -----------\n",
    "max_epoch = 25\n",
    "\n",
    "best_test_acc = 0\n",
    "for ep in range(max_epoch):\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for xb, yb in tqdm(train_loader):\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        y_hat = model(xb)\n",
    "        loss = loss_fn_c(y_hat.squeeze(), yb)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        opt_c.step()\n",
    "\n",
    "        opt_c.zero_grad()\n",
    "\n",
    "        epoch_loss += loss\n",
    "\n",
    "    print(\"Epoch: \", ep+1, \" Training Loss: \", epoch_loss.item())\n",
    "\n",
    "\n",
    "    #----------- Validation -----------\n",
    "\n",
    "    val_labels = []\n",
    "    val_pred = []\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    val_epoch_loss = 0\n",
    "\n",
    "    for xb, yb in tqdm(val_loader):\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        y_hat = model(xb)\n",
    "        loss = loss_fn_c(y_hat.squeeze(), yb)\n",
    "\n",
    "        val_epoch_loss += loss\n",
    "\n",
    "        val_labels.extend(torch.round(yb).cpu().detach().numpy())\n",
    "        val_pred.extend(y_hat.argmax(dim=1).cpu().detach().numpy())\n",
    "\n",
    "\n",
    "    print(\"Validation loss: \", val_epoch_loss.item())\n",
    "    print(\"Validation accuracy: \", accuracy_score(val_labels, val_pred)*100)\n",
    "\n",
    "\n",
    "    if ep > 15 and prev_val_loss - val_epoch_loss.item() > 0.05:\n",
    "        print(\"Saving Model\")\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")\n",
    "    \n",
    "    prev_val_loss = val_epoch_loss.item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pytorch.org/docs/stable/notes/faq.html#my-model-reports-cuda-runtime-error-2-out-of-memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Jun  1 2022, 11:38:51) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82c36bf2dc7bc97628b9e43543d03433a2e60a09cf06bbc88105c7bffe751e99"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
